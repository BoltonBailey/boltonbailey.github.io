<h1 id="statistical-democracy">Statistical Democracy</h1>
<!-- title: "Statistical Democracy" -->
<!-- draft: false -->
<p>From <a href="https://mason.gmu.edu/~rhanson/altinst.html">Robin
Hanson’s page on “alternative institutions”</a></p>
<blockquote>
<p>Pick a jury at random to decide an election</p>
</blockquote>
<p>Unfortunately, the link is broken. I’ll try to reverse engineer the
proposal and the arguments behind it.</p>
<h2 id="why-we-might-want-to-decide-an-election-by-jury">Why we might
want to decide an election by jury</h2>
<p>It’s widely accepted that for some electoral systems, votes of some
individuals are more decisive than others. In US Presidential elections,
for example, many states are politically one-sided enough that the
outcome of the election in that state isn’t in doubt, or small enough
that the outcome, whatever it may be, is unlikely to matter. It’s
therefore widely accepted that the election is likely to come down to
voters in “swing states”, whose votes can be as many as three orders of
magnitude more likely to affect the outcome (see <a
href="http://www.stat.columbia.edu/~gelman/research/published/probdecisive2.pdf">Gelman
et al.</a>).</p>
<p>This being the case, one might wonder why we bother holding elections
in non-swing states at all. After all, voting is a time-consuming
process. One could argue that even though the chance might be small, it
would be unfair to remove a state from the process entirely, on the
grounds that there would then be no political accountability of the
politicians to constituents of that state.</p>
<p>We ask, could there be a way to save the time of a state’s voters
while still guaranteeing accountability?</p>
<p>Our answer is statistical: Suppose that a month or so before the
election, we choose a small fraction of the state’s voting eligible
population by lottery. We ask those voters to make their choice early.
We then assess whether, by an assessment of those votes, we can be
statistically confident in the outcome of the election to a confidence
of <span class="math inline">\(p = 10^{-11}\)</span> (this being the
lowest probability of a single vote affecting the outcome of the
election found by Gelman et al.). If we can make such an assessment,
then we cancel the election and treat this as the outcome.</p>
<p>How many voters would need to vote early to make such an assessment?
In California’s 2020 presidential election, 63.48% of voters voted for
Biden. If we assume this proportion of early lottery-voters were to vote
for Biden, then fewer than 600 voters would be needed to conclude that
Biden won at this confidence. In order to be confident that we would be
able to make this conclusion even with a statistical fluctuation in the
number of voters, we could double this to 1200. That’s still less than
0.008% of the 17.5 million Californians who actually voted.</p>
<h3 id="some-cons-and-counterpoints">Some Cons and Counterpoints</h3>
<p>As a counterpoint, one could argue that the time constraints of
voting are actually a feature rather than a bug: Since the probability
of affecting the outcome is so low, the only reason to vote is out of an
altruistic spirit, and this ensures that voters will vote for the best
candidate, rather than one whose policies will benefit them personally.
As a counter to this counter, one could argue that the time constraints
of voting disenfranchise the underpriveliged, <a
href="https://www.brennancenter.org/our-work/research-reports/waiting-vote">for
whom voting takes especially long</a>. One could also argue that being
selected for the jury could be the impetus for a voter to research the
candidates better.</p>
<p>Another counterpoint: The random selection process leaves the door
open for potential skullduggery in the choice of voters. But there are
plenty of cryptographic techniques that allow for fair selection of
randomness. To counter this further, note that <em>even without</em>
this process, there was still controversy about the extent to which
cheating happened in the 2020 election. In fact, one could argue that
having fewer voters could allow closer scrutiny of the voting process,
and allay some of these fears.</p>
<h3 id="open-questions">Open questions</h3>
<p>Under the electoral college, what would be the optimal number of
voters to sample from each state? What would the backtested probability
of the outcome differing from the situation where everyone votes?</p>
<h2 id="statistical-democracy-for-daos">Statistical Democracy for
DAOs</h2>
<p>Getting a change to happen for the electoral system on a national
level ultimately seems unlikely. Are there other venues where these
ideas might be useful?</p>
<p>We turn to the blockchain, and DAOs with on-chain governance. The DAO
community is already very interested in innovation in decision-making,
so they might be more receptive to the statistical democracy idea.
Beyond that, there is a more concrete reason for DAOs to want to
minimize voting: rather than time, the cost for voting in a DAO is cold,
hard cryptocurrency in the form of transaction fees.</p>
<h3 id="considerations">Considerations</h3>
<p>Governance algorithms for DAOs must be expressed in code, so let’s
take the chance to analyze this problem more formally. There are a
variety of settings one could choose:</p>
<ul>
<li>Do all voters have equal power?
<ul>
<li>If not, does power take the form of a weight, as in
one-token-one-vote or delegation?</li>
</ul></li>
<li>What guarantees on getting the “right” outcome do we want to
provide?
<ul>
<li>Do we want the probability to be near 99% or near 99.9999%?</li>
<li>What distribution is this probability taken over? Randomness of the
election organizer? Some prior on the expected votes of the
individuals?</li>
</ul></li>
<li>What guarantees on the number of voters do we want to provide?</li>
<li>What guarantees on the number of rounds of asking for more votes do
we want to provide?</li>
<li>What guarantees on the time complexity of the election organizer do
we want to provide?</li>
</ul>
<h3 id="a-setting">A Setting</h3>
<p>Here is a setting which seems nontrivial:</p>
<p>We assume an election organizer who only tries to minimize the number
of queries to individual voters. These queries can be made one at a time
and an arbitrary amount of compute and randomness can be spent to
determine who to query next. The election has two outcomes. Each voter
has a weight, and when queried, votes yes or no. The “correct” outcome
for the election is yes if, when all voters are queried, the total
weight of yes voters is above a fixed threshold. The probability over
the organizer’s randomness that the returned outcome is different from
the correct outcome must be &lt; epsilon (for any choice of voter
preferences).</p>
<p>For the purposes of minimizing the expected number of queries of the
algorithm, we assume the prior that there is some uniformly-drawn p from
[0,1] representing the “goodness of the proposal” and all voters vote
yes with prob p independently, minimize the expected number of
queries</p>
<h3 id="an-approach">An approach</h3>
<p>Note that, because the set of possible total weights on yes is
discrete, there is a nonzero difference between the maximum possible
total yes weight leading to “no” and the minimum possible yes weight
leading to “yes”</p>
<p><span class="math display">\[t_{max, no} &lt; t_{min,
yes}\]</span></p>
<p>Consider, then, the following algorithm</p>
<ol type="1">
<li>In each loop, select a voter randomly by weight.</li>
<li>Add the selected voter’s vote to a running total of votes.</li>
<li>Run two <a
href="https://auai.org/uai2016/proceedings/supp/270_supp.pdf">sequential
tests</a> to determine whether the proportion of weight voting yes is
<span class="math inline">\(\ge t_{min, yes}\)</span> or <span
class="math inline">\(\le t_{min, no}\)</span>, each with probability of
error <span class="math inline">\(\epsilon/2\)</span>. When one test
returns, choose the selected outcome accordingly.</li>
</ol>
<p>Note that the number of queries is less than the number of loops,
since if we re-sample a voter, we don’t have to query them again, we can
use their vote from before. The loop cannot be expected to continue
forever due to the separation between <span
class="math inline">\(t_{max, no}\)</span> and <span
class="math inline">\(t_{min, yes}\)</span>.</p>
<p>This protocol is not optimal. For one thing, if there is one “whale”
whose voting power decides the election all on its own, the optimal
protocol would be to query that voter and only that voter and not bother
potentially sampling voters with less power. Here is another protocol,
which takes this into account:</p>
<ol type="1">
<li>For a fixed <span class="math inline">\(k\)</span>, query the top
<span class="math inline">\(k\)</span> voters <span
class="math inline">\(v_1, \dots, v_k\)</span>, with weights <span
class="math inline">\(w_1, \dots, w_k\)</span> in order of decreasing
weight.</li>
<li>If, at any point, the outcome is determined with certainty,
terminate. Otherwise, let <span class="math inline">\(t_{yes,k}\)</span>
be the total yes vote weight among these and <span
class="math inline">\(t_{no,k}\)</span> the total no vote.</li>
<li>Revert to a loop selecting remaining voters randomly by weight. Let
the <a
href="https://auai.org/uai2016/proceedings/supp/270_supp.pdf">sequential
test</a> determine whether the proportion of weight among these voters
voting yes is <span class="math inline">\(\ge \frac{t_{min, yes} -
t_{yes, k}}{1 - \sum_{i\le k} w_i}\)</span> or <span
class="math inline">\(\le \frac{t_{no,k}- t_{min, no}}{1 - \sum_{i\le k}
w_i}\)</span>, each with probability of error <span
class="math inline">\(\epsilon/2\)</span>. When one test returns, choose
the selected outcome accordingly.</li>
</ol>
<p>Is this new protocol optimal? If not, what is the optimal protocol,
and is there a simple way of describing it? Is this or the previous
protocol at least asymptotically optimal in some sense? For any of these
protocols, how can we minimize their expected time complexity?</p>
