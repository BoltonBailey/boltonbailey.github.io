<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Perfect Minesweeper</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header>
<h1 class="title">Perfect Minesweeper</h1>
<p class="date">2018-01-01T13:37:00-08:00</p>
</header>
<h2 id="a-deceptively-imperfect-strategy">A Deceptively Imperfect Strategy</h2>
<p><a href="https://www.youtube.com/watch?v=cGUHehFGqBc">This youtube video from Code Bullet</a> claims to create a ‚Äúperfect‚Äù minesweeper bot. I really like Code Bullet‚Äôs videos, but in this case, the title is a bit dishonest. A perfect bot would be one that maximizes the probability of winning in any situation, but Code Bullet almost immediately admits he is unsure if his bot really is perfect.</p>
<p>The bot in the video is what we might call a ‚Äúgreedy-probability‚Äù bot. It implements the following features:</p>
<ol type="1">
<li>It flags any square which must be a mine</li>
<li>It searches any square which cannot be a mine</li>
<li>When there is no square which can be determined with certainty, it guesses a square with minimum probability of being a mine.</li>
</ol>
<p>It is indeed not too hard to create a greedy-probability bot. As the video explains, one can determine the probability of a given square being a mine relatively quickly in most cases (despite the problem being NP-Hard in general) by enumerating all possible layouts for mines in squares adjacent to clues and then using combinatorics. A nice implementation which I have been playing around with is <a href="https://mrgris.com/projects/minesweepr/">this one</a>, which also provides a sweet demo.</p>
<p>However, greedy-probability strategies are actually provably suboptimal, as we shall see.</p>
<h2 id="when-guesses-are-optimal">When Guesses are Optimal</h2>
<p>Consider the following layout of mines and solved squares:</p>
<figure>
<img src="img/example1.png" alt="Image" /><figcaption>Image</figcaption>
</figure>
<p>Note that in the squares marked A there exists exactly one mine, and there is a 50/50 chance of the mine being in either square.</p>
<p>Now a more subtle point: there is no square that can be searched that will reveal more information about which of the A-marked squares contains the mine. In particular, if we search the B-marked squares and we determine the contents of all other squares, the only thing the information from the B-marked squares will tell us is what we already know: that exactly one of the A-marked squares is a mine. So no matter what, the decision of which A-marked square to search first will come down to a 50% risk of hitting a mine.</p>
<p>Furthermore, no matter which A square is searched, it will reveal the same information if it turns out to be safe, namely,</p>
<ol type="1">
<li>We will know the other A-marked square is a mine.</li>
<li>We will know the number of mines in the B-marked squares.</li>
</ol>
<p>For example, if there is one mine in the B marked squares, the top A square is either a mine or a 5, and the bottom A square is either a mine or a 2.</p>
<p>Since the risk is unavoidable, and the information provided is the same, it is therefore optimal to search one of these squares (<em>which</em> one does not matter) before proceeding. In fact, since it is generally better not to waste time, you should always make these guesses first <em>even if</em> there are squares that can be solved outright. If you‚Äôre going to explode, you might as well do it now.</p>
<h2 id="the-imperfection-of-a-greedy-probability-strategy">The imperfection of a Greedy-Probability strategy</h2>
<p>Now consider the following layout, with 4 mines left:</p>
<figure>
<img src="img/example2.png" alt="Image" /><figcaption>Image</figcaption>
</figure>
<!--  (this layout of course, has a nonzero probability of occurring in any given game of minesweeper) -->
<p>By our arguments above, we know it is optimal to guess in the A-marked and E-marked squares. In fact, this is strictly better than the alternative: If one of the B-, C- or D-marked squares in the middle is chosen, there is always the possibility that there is a mine in that square, and the one above/below it (it‚Äôs letter partner). In this scenario, solving the A- and E-marked first would have alerted us to the location of all remaining mines, immediately winning without incurring any additional risk.</p>
<p>To calculate more precisely, there is a <span class="math inline">1/15</span> chance that for each of B, C, and D that there are bombs in both those squares. In that case, conditional on successful A and E guesses, the game is won. Otherwise, there is one column with no mines, and the other columns have 1 each, and we can see that these columns will be 50% guesses in the conditional on successful A and E guesses. Thus, the optimal win rate in this position is 10%.</p>
<p><br /><span class="math display">$$ \frac14 (1/5 \cdot 1 + 4/5 \cdot 0.25)  = 0.1 = 1/10$$</span><br /></p>
<p>However, a greedy-probability strategy will never choose one of the left or rightmost squares, since the B-, C- and D-marked squares squares each have probability 2/6 = 33% of having a mine, which is less than the 50% of the A- and E-marked squares. And since the first guess incurs 33% chance of loss, and the A and E guesses are inevitable, the most winrate a greedy-probability strategy can have is 1/12 = 8.3%.</p>
<h2 id="another-helpful-tool-for-minesweeper-analysis">Another Helpful Tool for Minesweeper Analysis</h2>
<p>The fact that it is usually quick to assign probabilities to all squares means we can formulate a game which is equivalent to minesweeper, but replaces the hidden-information aspect with stochasticity.</p>
<p>A position in <em>smoothed loss minesweeper</em> consists of a minesweeper position <span class="math inline">ùí´</span> along with a number <span class="math inline"><em>x</em></span>. When a play is made on <span class="math inline">(ùí´,‚ÄÜ<em>x</em>)</span> we evaluate the probability <span class="math inline"><em>p</em></span> that this move would result in a loss if played on <span class="math inline">ùí´</span>. We then reveal a number in the selected cell as if we had conditioned on that cell having no mine, and we replace <span class="math inline"><em>x</em></span> with <span class="math inline"><em>p</em><em>x</em></span>. One can see by induction that the equity of <span class="math inline">(ùí´,‚ÄÜ<em>x</em>)</span> in smoothed loss minesweeper is just the equity of <span class="math inline">ùí´</span> times <span class="math inline"><em>x</em></span>.</p>
<p>This reduces the problem of playing minesweeper to a Markov Decision Process, which we can then approach with various techniques from reinforcement learning.</p>
<h2 id="a-proposal-for-creating-a-good-rl-based-ai">A Proposal for Creating a Good RL-Based AI</h2>
<p>An RL approach that seems to be promising for this task is Deep Q-learning: We create a Neural Network which attempts to predict the equity of a given position. We train this network by having it play minesweeper and adjusting the weights so that the equity of any position is close to the maximum over all moves from that position of the predicted equity of that move. We also modify the algorithm so that whenever there is a move that is provably optimal (perhaps due to the above reasoning), we simply make that move rather than query the network about it.</p>
<p>This network might have convolutional structure and take input in the form of the cell values or the precomputed mine probabilities (note that the value of an opened a cell is always equal to the sum of the adjacent mine probabilities). It might be wise to have the output be in the form of the logarithm of the equity, so that if the log-probability of a win can be computed for two disjoint sections, those log-probabilities can be added to get the final equity.</p>
<h2 id="pruning-by-move-comparison">Pruning by move comparison</h2>
<p>Suppose that we have created an AI using a combination of Q-learning and hard-coded optimal guesses that is very good at predicting correct moves. In a certain position, the AI predicts move A is optimal, and we would like to prove quickly that move A is superior to move B. One way we might be able to do this is by showing that if move A is carried out first and move B is only carried out if move A does not reveal B, then the performance is strictly better.</p>
<p>Explicitly, these are the two strategies we would like to compare</p>
<p>Strategy <span class="math inline"><em>Œ±</em></span></p>
<ol type="1">
<li>Play Cell A</li>
<li>Reveal any cells that are safe</li>
<li>If this process determines that cell B is a mine, then play optimally</li>
<li>Otherwise, play Cell B, then play optimally.</li>
</ol>
<p>And</p>
<p>Strategy <span class="math inline"><em>Œ≤</em></span></p>
<ol type="1">
<li>Play Cell B</li>
<li>Thereafter, play optimally</li>
</ol>
<p>To compare these strategies, we consider 4 possibilities for the contents of these cells, depending on the two events <span class="math inline"><em>A</em></span> and <span class="math inline"><em>B</em></span> of there being a mine in cell <span class="math inline"><em>A</em></span> or <span class="math inline"><em>B</em></span></p>
<ul>
<li>Event <span class="math inline"><em>AÃÑ</em><em>BÃÑ</em></span>: Cell A and Cell B are safe. In this case strategy <span class="math inline"><em>Œ±</em></span> has weakly better equity since it will reveal both cells and have strictly more information in the A case.</li>
<li>Event <span class="math inline"><em>AÃÑ</em><em>B</em></span>: Cell A is safe and Cell B is mined. Strategy <span class="math inline"><em>Œ±</em></span> will have some equity depending on the probability that cell B is determined after revealing cell A. Strategy <span class="math inline"><em>Œ≤</em></span> will have 0 equity</li>
<li>Event <span class="math inline"><em>A</em><em>BÃÑ</em></span>: Cell A is mined and Cell B is safe. Strategy <span class="math inline"><em>Œ±</em></span> will have 0 equity and strategy <span class="math inline"><em>Œ≤</em></span> with have some nonzero equity.</li>
<li>Event <span class="math inline"><em>A</em><em>B</em></span>: Cell A and Cell B are both Mined. Both strategies have 0 equity.</li>
</ul>
<p>Note that just as we can combinatorially evaluate the probabilities of individual cells being mines (usually quickly in practice) we can combinatorially evaluate the probabilities of each of these outcomes. We would like to show that the expected value of the equity <span class="math inline"><em>V</em></span> of strategy <span class="math inline"><em>Œ±</em></span> is greater than that of strategy <span class="math inline"><em>Œ≤</em></span>. This can be expressed by the inequality</p>
<p><br /><span class="math display">ùîº[<em>V</em><sup><em>Œ±</em></sup>]‚ÄÑ‚â•‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>]</span><br /> or more verbosely <br /><span class="math display">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>B</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>A</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>A</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>B</em></sub>‚ÄÑ‚â•‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>AÃÑ</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>B</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>B</em></sub></span><br /></p>
<p>Clearly, we have <span class="math inline">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>A</em><em>B</em>]‚ÄÑ=‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>B</em>]‚ÄÑ=‚ÄÑ0</span>. Furthermore <span class="math inline">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>A</em><em>BÃÑ</em>]‚ÄÑ=‚ÄÑ0</span> and <span class="math inline">ùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>AÃÑ</em><em>B</em>]‚ÄÑ=‚ÄÑ0</span>. Thus, the above is equivalent to</p>
<p><br /><span class="math display">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>B</em></sub>‚ÄÑ‚â•‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>BÃÑ</em></sub>‚ÄÖ+‚ÄÖùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>BÃÑ</em></sub></span><br /></p>
<p>and since in event <span class="math inline"><em>AÃÑ</em><em>BÃÑ</em></span>, the player is left with more information if they follow strategy <span class="math inline"><em>Œ±</em></span>, we have <span class="math inline">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]‚ÄÑ‚â•‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>AÃÑ</em><em>BÃÑ</em>]</span> so the above is implied by</p>
<p><br /><span class="math display">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>B</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>AÃÑ</em><em>B</em></sub>‚ÄÑ‚â•‚ÄÑùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>BÃÑ</em>]‚ÄÖ‚ãÖ‚ÄÖ<em>p</em><sub><em>A</em><em>BÃÑ</em></sub></span><br /></p>
<p>We can then attempt to prove this inequality by upper bounding <span class="math inline">ùîº[<em>V</em><sup><em>Œ≤</em></sup>|<em>A</em><em>BÃÑ</em>]</span> and lower bounding <span class="math inline">ùîº[<em>V</em><sup><em>Œ±</em></sup>|<em>AÃÑ</em><em>B</em>]</span>, using techniques described in the next section.</p>
<p>Hopefully, this will allow a computer to resolve positions which are common in the middlegame: The lowest probability cell is on the edge of the frontier and has a 4-9% chance of being a mine while the vast majority of cells have no clues and are around 20% to have a mine.</p>
<h2 id="a-proposal-for-creating-an-actually-perfect-ai">A Proposal for Creating an Actually Perfect AI</h2>
<p>We now put together these ideas to describe how to make an AI that plays Perfectly.</p>
<p>Using the Q-learning player we can get a statistical lower bound on the equity of any position by doing a rollout. Technically this means our bot will only play perfectly with some high probability in the sample. But unlike the previous approaches, this really is only a technicality: we can set the probability of failure to be less than the probability of the computer being struck by a meteorite.</p>
<p>One can also get an upper bound on the equity of a position by looking at the lowest risk cell, and possibly factoring in probabilities of fifty-fifty positions arising elsewhere in the board</p>
<p>Once we have naive bounds on the equities of positions, we can improve them through tree search. Once our bounds are good enough, we can begin to prune the tree, either by the technique described above, or simply using the bounds explicitly. Pruning will make the tree search more efficient and will refine the equity estimates faster. If these effects feed off of each other enough, the program will find the best move in the position in a reasonable amount of time.</p>
<p>Since the <a href="https://mrgris.com/projects/minesweepr/">mrgris blog post</a> shows that the equity of expert minesweeper is ~37.8%, and most cells in a given position have about a 20% chance of being a mine, we can likely prune most branches of the opening position after <span class="math inline">log<sub>0.8</sub>(0.3)‚ÄÑ‚âà‚ÄÑ4.36</span> moves. With a 16 x 30 board, this is <span class="math inline">(16‚ÄÖ‚ãÖ‚ÄÖ30)<sup>4.36</sup>‚ÄÑ‚âà‚ÄÑ4.9‚ÄÖ√ó‚ÄÖ10<sup>11</sup></span> positions to consider at least. Even fewer nodes are needed if the equity is actually larger or with pruning.</p>
<p>One way that this scheme could fail is the case where two choices are so close in equity that even with an oracle for the perfect move in every subsequent position, it is infeasible to statistically bound the equities tightly enough to differentiate between them.</p>
<h2 id="speculation-and-other-notes">Speculation and other notes</h2>
<p>Interestingly, the game implemented by <a href="http://minesweeperonline.com/">this website</a> (which I used to create the pictures) has a slight quirk: the first tile chosen always has 0 mines next to it. Usually, the first square is never a mine, but might not be a 0 square (this is strategically equivalent to a uniform distribution of mines, since there is no point in worrying if the first square can be a mine).</p>
<p>One way human players might benefit from a computer solution to the game would be opening theory. Humans could memorize the optimal moves in the 100-1000 most common positions under optimal play. Note however, that the move that gives the highest chance of winning might not be best from a speed records perspective. When trying to set a record, you want to give up early on games that go poorly. Thus, it might be best to just click a few central locations until you hit a mine or reveal enough squares to make the run worth playing.</p>
<p>Humans playing the game might also benefit from seeing the neural network‚Äôs response to various positions. In particular, an understanding of the temperature of a position, in the statistical mechanical sense, might be beneficial.</p>
<h3 id="my-predictions-for-best-first-move">My Predictions for best first move</h3>
<p>It would be interesting to know what the optimal opening move in expert minesweeper is. Writing before making the bot, my priors on this are:</p>
<ul>
<li>75%: Some cell on or adjacent to the edge: Human players seem to think that it‚Äôs best to start on the corner since you can do more reasoning there.
<ul>
<li>50% 1-1: You have about a 50% chance of getting a 0 and immediately expanding. Otherwise, you have a high probability of a 1, and the 1-3 cell becomes attractive.</li>
<li>20% 2-2 cell: The only way to get a risk less than 20% on the second move if you don‚Äôt hit a zero is if you reveal a 1 not on an edge or corner, and presumably once you do this, you choose an adjacent cell. Playing 2-2 and then 1-1 in response to a 1 is guaranteed to reveal at least seven cells in total. I used to think this was the best opener but I may have been biased by the minesweeperonline.com version of the game</li>
<li>5% Some other cell near the corner: Like the 1-2 or 2-3 cell. There may be some funky interaction that makes these cells good, sort of like how joseki in go have no clear surface-level explanation. Just to put numbers on this, I‚Äôll say
<ul>
<li>3% 1-2 cell</li>
<li>1.5% 3-2 cell</li>
<li>0.5% some other cell near within the 5x5 corner region</li>
</ul></li>
</ul></li>
<li>20% 8-15 cell: Perhaps the human intuition is biased in favor of simpler positions, and th real truth is that playing in the middle is correct. If the optimal first cell is not on the corner I would expect the answer to be the exact center or the board, since the space of tiles ‚Äúreachable from the initial reveal without guessing‚Äù seems to depend on percolation theory, so it would seem more centralization is better.</li>
<li>4% edge cell: Perhaps the best strategy is a compromise between the center and corner. This seems unlikely to me though, if the principle of ‚Äúmake early deductions easy‚Äù is really correct, wouldn‚Äôt the corner just be better? If this possibility turns out to be correct, I would expect the center of the longer edge to be optimal.
<ul>
<li>3% 2-15 cell: (since it allows the follow-up 1-15 after 1)</li>
<li>1% 1-15 cell.</li>
</ul></li>
<li>1% some other cell: It‚Äôs hard to come up with an explanation of why another cell I haven‚Äôt mentioned would be optimal. In particular, if the center play is correct, I can‚Äôt see a reason to just play near the center, rather than as close as possible to it.</li>
</ul>
<p>In general, I assume that the optimal guess in any position is a balance of likelihood of bomb and information gained. I often make the mistake of making a guess that I could deduce beforehand would give me no information if correct. I think if you have a guarantee of resolving at least one other square after a guess, that guess is much more attractive. It‚Äôs also interesting to ask what to do when the big block of squares with no guesses adjacent is less likely than any of the squares adjacent to information: is it right to stay near your previous guesses, or to branch out to the center of the empty space? This is analogous to the corner vs.¬†center question.</p>
</body>
</html>
